{
 "metadata": {
  "name": "",
  "signature": "sha256:fa34d8a603df656e3029e556758357f97768d71926fb4a9400a84943d874fb71"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "**AM 207**: Homework 4"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_ _ _ _ _\n",
      "\n",
      "Verena Kaynig-Fittkau & Pavlos Protopapas <br>\n",
      "Handed out: Thursday, February 26th, 2015<br>\n",
      "Due: 11.59 P.M. Wednesday March 4th, 2015\n",
      "\n",
      "**Instructions**:\n",
      "\n",
      "+ Upload your answers in an ipython notebook to the dropbox.\n",
      "\n",
      "+ The notebook filename should have the format AM207_YOURNAME_HW4.ipynb\n",
      "\n",
      "+ Your code should be in code cells of your ipython notebook. Do not use other languages or formats without permission from the TFs. Any special libraries should be included with your code - the notebook should run \"as is\". \n",
      "\n",
      "+ If you have multiple files (e.g. you've added code files and images) create a tarball or zip for all files in a single file and name it: AM207_YOURNAME_HW4.tar or AM207_YOURNAME_HW4.zip\n",
      "\n",
      "+ Please remember that your solution is supposed to be a report. Provide clear explanations of your ideas and the way you  approached the solution. Clearly identify the question or part of a question that you are answering. And please comment your code!\n",
      "_ _ _ _ _"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Question 1: Jumping between mountains"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use the M-H algorithm to sample from the normal distribution: $p(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}$. \n",
      "\n",
      "\n",
      "\n",
      "(a) Select a proposal distribution of $q(x^*|x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x^*-x)^2}{2\\sigma^2}}$. Let the starting point be $x_0=-1000$ and step size be $\\sigma=1$. Now, run the M-H algorithm for 10,000 samples. Show the trace plot of your algorithm. What is an appropriate burn-in sample size?\n",
      "\n",
      "(b) Perform Geweke tests, one for all samples and one for samples after burn-in. Do the results differ? If so, explain why.\n",
      "\n",
      "Now, we would like to sample from a mixture normal distribution:  $p(x) = \\frac{1}{2\\sqrt{2\\pi}} e^{-\\frac{(x-6)^2}{2}} + \\frac{1}{2\\sqrt{2\\pi}} e^{-\\frac{(x+6)^2}{2}}$. \n",
      "\n",
      "(c) Please visualize the density function, $p(x)$, from $-10$ to $10$.\n",
      "\n",
      "(d) Using a starting point of $x_0=-6$ and a proposal distribution of $q(x^*|x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x^*-x)^2}{2\\sigma^2}}$ with $\\sigma=1$, run the M-H algorithm for 10,000 samples.\n",
      "Choose an appropriate burn-in sample size, show the trace plot, and perform the Geweke test on the remaining samples. Just looking at these two results, what do you see? Does the MCMC converge?\n",
      "\n",
      "(e) Now plot the histogram of the remaining samples. Is the M-H algorithm converging?\n",
      "\n",
      "(f) Finally, using $\\sigma=4$ for the proposal distribution, re-answer problems (d) and (e). For the Geweke test, try \n",
      "segments of 100 and 500 to calculate the means and variances. If the results differ, please explain why. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Question 2: Thinning of Chains"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A good performance test of the ability of a technique to sample the full\n",
      "parameter space is to test the sampling of the Rosenbrock 'Banana' Function.\n",
      "Consider the following specific form of a Banana PDF,\n",
      "\n",
      "$ p(X) \\propto {\\rm exp} \\left[ - \\frac{1}{2a^2} \\left(\\sqrt{x_1^2 + x_2^2} -1 \\right)^2 -  \\frac{1}{2b^2} \\left(x_2  - 1 \\right)^2  \\right] $ where $a=0.1$ and $b=1$.\n",
      "\n",
      "(a) Visualize the Rosenbrock 'Banana' Function.\n",
      "\n",
      "(b) Using the proposal function,\n",
      "\n",
      "$q(Y|X) = \\frac{1}{2 \\pi \\sigma^2} {\\rm exp}\\left[-\\frac{1}{2 \\sigma^2} ((y_1-x_1)^2+(y_2-x_2)^2) \\right] $ \n",
      "\n",
      "with $\\sigma = 1$, construct a M-H algorithm to produce $N=10,000$ samples from $p(X)$. Let the starting point be $X=(-1,0)$. Plot the results and identify an appropriate burn-in sample size.\n",
      "\n",
      "(c) The effective sample size of a M-H result is defined as:\n",
      "\n",
      "$\\rm{N_{eff}} =\\frac{N}{1+2\\sum_{t=1}^\\infty \\rho_t}$ \n",
      "\n",
      "where $\\rho_t = cor(X_i, X_{i+t})$  is the autocorrelation of the sequence at lag t. For simplicity, we only consider the chain of $x_2$, that is $\\rho_t = cor(x_{i,2}, x_{i+t,2})$ [HINT: Python's numpy.corrcoef computes correlation]. For simplicity, use an upper bound of 100 for lag:\n",
      "\n",
      "$\\rm{N_{eff}} =\\frac{N}{1+2\\sum_{t=1}^{100} \\rho_t}$. \n",
      "\n",
      "Compute the effective sample size of the M-H samples.\n",
      "\n",
      "(d) Compute the sample mean (after burnin)  $\\bar{x}_2$. Repeat (b) for 100 times and calculate the variance of $\\bar{x}_2$. For simplicity, choose the same burn-in sample size for each run.\n",
      "\n",
      "(e) Now, perform  thinning, i.e. using 1 out of every 10 samples. Construct a M-H algorithm that yields $N=10,000$ samples (after thinning). Plot the results and choose an appropriate sample size.\n",
      "\n",
      "(f) Compute the effective sample size with thinning and compare it with the result from (c). Do you see any improvement? Explain why.\n",
      "\n",
      "(g) Repeat (d) with thinning,  and compare the variances. Do you see any imporvement? Explain why."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Question 3: IMDB top five"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we ask individuals to remember the  order of the top five movies on IMDB. When asked afterward, some will not report the correct order, and the mistakes they make can be captured by simple probabilistic models.\n",
      "  \n",
      "Let's say that the top five movies are:  *The Shawshank Redemption*,*The Godfather*,  *The Godfather: Part II*, *The Dark Knight*  and  *Pulp Fiction*. This true ordering will be represented by a vector $\\omega =$ (1,2,3,4,5). \n",
      "\n",
      "When someone ranks the movie as $\\theta$ , the Hamming distance between that rank and the true rank is \n",
      "  \n",
      "$d(\\theta, \\omega) = \\sum_{i=1}^5 I_{\\theta_i\\neq \\omega_i}$. \n",
      "  \n",
      "For example, if $\\theta$= (2,3,5,4,1), then $d(\\theta, \\omega)=4$, because only *The Dark Knight* is ranked correctly. \n",
      "\n",
      "Suppose the probability of a guess (expressed as $\\theta$) is \n",
      "\n",
      "$ p(\\theta | \\omega, \\lambda) \\propto  e^{-\\lambda d(\\theta, \\omega)} $.\n",
      "\n",
      "(a) Implement an M-H algorithm to produce sample guesses from 500 individuals with different $\\lambda=0.2, 0.5, 1.0$. What are the top five possible guesses?\n",
      "\n",
      "(b) Compute the probability that *The Shawshank Redemption* is ranked as the top 1 movie by the M-H algorithm. Compare the results for different $\\lambda$. What do you find?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}